# Provisioning a demo Web project in Google Compute Platform

## Overview

This project aims to demonstrate how to set up an infrastructure for a small web application that has multiple http
frontends (with load-balancing and auto-scaling), and a single database backend.

Although it is not that difficult to build this via the GUI, the secondary goal is to accomplish all this in an
automated manner, so this whole infrastructure shall be replicable easily and without human interaction.


## The architecture

The installation of this infrastructure is based on the Google Cloud Platform, and all its parts will be deployed in a
single Project, so it will be completely separate from any other activities of our cloud account.

The files `provisioner.pem`, `provisioner.openssh.pub`, `service_account.json` contain credential information,
which has to be actualised with valid values before use.

For the autoscaling feature the frontends must be fully cloneable, so they will be a Managed Instance Pool, and for
that we need an Instance Template.


## Credentials

As the provisioner user must have access to the instances of the project, its ssh key needs to be added on project
level.

To do this, open the GCP web console, choose the project at the top, then on the side bar choose
[Compute Engine / Metadata / SSH Keys](https://console.cloud.google.com/compute/metadata/sshKeys).

Here you can *Edit* the list of keys, and *Add item* in the format `ssh-rsa AAAA.... username@somewhere.com`,
just like as you would add to a `.ssh/authorized_keys` file. The username will be the same as in the trailing
`user@...` part (the `...somewhere` part is not relevant).


## Creating the instance template of the frontend

This step has to be performed only once, and later the future webservers can just instantiate it.

For this reason, this step resides in a separate folder: `00_create_websvr_golden_template`.

That template is generated by creating a 'golden' instance, setting up all the packages and building all prerequisites
on it, and then using its disk to create a 'golden' image, and then we define the instance template as having the same
instance parameters and refer to this image when cloning the new disks on instantiation.

* `ansible-playbook -i inventory.gcp_compute.yaml 0_create_instance_template.yaml -v`

## To Be Continued ...


## Notes

### Why not Terraform

Terraform aims to achieve a 'desired' state of interdependent resources and it's quite an adequate tool for it.  But its
main concept is to be **declarative**, meaning that in the configuration we describe that single desired *state* of the
system, and not the way that leads to it.

You can't simply describe a *recipe* like:

1. Create an instance
2. Configure it
3. Create a template from it
4. Stop the instance
5. Destroy it

The reason of being unable to do so is that there is no single *desired* state of that instance. Step 1 wants to achieve
that it exists and is RUNNING, then Step 2 wants to achieve ...  something that is not represented in the state of the
instance, then Step 4 wants to achieve that it's STOPPED, and finally Step 5 wants to achieve that it doesn't even exists.

Sure, it can be done via Terraform (by using `null_resource`-s), but it means actively hacking the original concept,
essentially *tricking* the DAG-resolver to perform the *sequence of steps* we want.

Basically we are mis-using a declaratic mechanism to do some definitely programmatic task. Besides, its config language
HCL isn't quite orthogonal (a feature that works with *this* won't necessarily work with *that*), so IMO Terraform isn't
designed to describe and support infrastructures that

* Have arrays of higher-level resource structures, or
* Needs sequential *recipes* that do multiple state transition on the same resources

It can be hacked to do that, but it'll be much more counterintuitive to read, even than a shell script, and it takes
more effort to *force* Terraform to do what we want than what it takes to do the actual job itself.

